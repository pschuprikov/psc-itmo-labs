\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}

\author{Чуприков Павел Сергеевич \\ группа 4539}
\title{Отчет по курсовой работе по предмету: <<Информационный поиск>>}
\begin{document}
\begin{titlepage}
\thispagestyle{empty}
\begin{center}
Санкт-Петербургский национальный исследовательский университет 
информационных технологий, механики и оптики\\
\smallskip
Факультет информационных технологий и программирования\\
\smallskip
Кафедра компьютерных технологий\\
\vspace{2cm}
\large{Чуприков Павел Сергеевич}\\
\vspace{1cm}
\begin{LARGE}
Отчет о курсовой работе по предмету: <<Информационный поиск>>\\
\end{LARGE}
\vfill
\today
\end{center}
\end{titlepage}

\setcounter{page}{2}
\tableofcontents
\pagebreak
\section{Введение}
Информационный поиск изучает поиск документов, содержащих неструктурированные данные,
удовлетворяющий потребности пользователя. Взаимодействие пользователя и системы информационного 
поиска можно кратко описать следующим образом:
\begin{enumerate}
\item Пользователь вводит некоторый текстовый запрос, возможно имеющий 
специализированный синтаксис для поиска цитат или других подсказок поисковой системе.
\item В ответ система возвращает список документов, которые, предполагается, 
пользователь хотел увидеть в ответ на данный им запрос.
\end{enumerate}

Конвейер информационного поиска включает в себя множество подзадач, начиная
с получения документов из сети Интернет и индексации (процесс предобработки
документов, имеющий целью ускорить операции, необходимые в дальнейшем
для удовлетворения запросов пользователей), заканчивая ранжированием
(численная оценка полезности для пользователя найденных документов) и
обработкой реакции пользователя на предоставленную информацию.


В данной работе рассматривались следующие подзадачи, результаты работы
которых, тем не менее, можно наглядно продемонстрировать в изоляции от 
остального конвейера:
\begin{itemize}
\item Выбор инструментов и методов хранения данных;
\item Индексирование документов с информацией о позициях;
\item Поиск в индексе соответствующих запросу документов, включая:
    \begin{itemize}
        \item конъюнкцию запросов;
        \item цитатный поиск;
        \item поиск с заданным расстоянием между словами;
        \item поиск с мета-символами.
    \end{itemize}
\end{itemize}

Основным вопросом информационного поиска, оставшимся без внимания в данной работе, является ранжирование найденных документов.

\section{Постановка задачи}
\subsection{Выбор инструментов и методов хранения данных}
Сюда решено отнести задачи, напрямую не связанные с алгоритмами,
применяемыми в поиске, а отвечающие за хранение и доступ к структурам данным,
используемым в алгоритмах. Так как необходима обработка 
большого объема данных, то хорошая производительность, и экономное использование 
дискового пространства, стали основными требованиями к подсистеме хранения данных.

В качестве дополнительного критерия учитывалась также простота взаимодействия с 
базой данной при использовании языка \emph{Java}.

\subsection{Индексирование документов с позиционными данными}
Индекс, или точнее обратный индекс (англ.~inverted index) представляет собой структуру
данных, которая для каждого термина хранит список документов, в которых данный термин 
встречался. Для выполнения цитатного и поиска и указанной близостью в данной работе
необходимо также хранить информацию о конкретных позициях вхождения заданных терминов.
Эта структура данных должна эффективно выполнять операцию пересечения списков терминов, 
поскольку именно эта операция составляет основу информационного поиска и легко может стать
узким местом поисковой системы в целом.

Итак, во-первых, необходимо реализовать алгоритм построения индекса, 
удовлетворяющий следующим требованиям:
\begin{itemize}
\item необходимо сохранять информацию о конкретных позициях вхождений терминов в документ;
\item размер словаря терминов может не умещаться в оперативную память;
\item список вхождения отдельного термина может не умещаться в оперативную память;
\item возможно добавление новых документов к индексу;
\item построение индекса должно эффективно использовать имеющуюся систему хранения данных;
\end{itemize}

Во-вторых, необходимо, в координации с первой подзадачей, обеспечить выполнение
пересечений списков вхождений и обработку позиционных данных, используемых для
выполнения специфичных запросов из следующего подраздела.

\subsection{Поиск в индексе соответствующих запросу документов}
Требуется на основании двух предыдущих подзадач реализовать алгоритм
поиска документов, поддерживающий следующие виды запросов:
\begin{itemize}
\item конъюнкция запросов: \textbf{ориентированный граф};
\item цитатный запрос: \textbf{"ACM ICPC"};
\item запросы с заданной близостью: \textbf{девушка /6 военными};
\item запросы с метасимволами: \textbf{стр*труп}.
\end{itemize}

\section{Реализация}
В целом система представляет из себя трехслойную архитектуру, реализованную на языке \emph{Java}: 
\begin{itemize}
\item база данных --- \emph{Berkeley DB JE} + \emph{Java};
\item логика (индексирование, нормализация, поиск и т. д.) --- \emph{Java API for XML Web Services};
\item пользовательский интерфейс --- \emph{Java Server Faces}.
\end{itemize}

\subsection{Выбор инструментов и методов хранения данных}
Для хранения индекса и сопутствующей информации была выбрана база данных
\emph{Berkeley DB Java Edition}, использующая в качестве модели данных пары ключ-значение.
При выборе в качестве решающих выступили следующие факторы:
\begin{itemize}
\item хорошая производительность;
\item возможность компактного представления записей в базе данных;
\item встроенная поддержка составного парного ключа (окажется полезным при хранении индекса).
\item поддержка запросов \emph{upper bound}/\emph{bound};
\item простота интеграции с Java.
\end{itemize}

\paragraph{Обратный индекс.} Так как список вхождений каждого конкретного термина может 
не помещаться в оперативной памяти компьютера, решено было разбить 
упорядоченные списки вхождений термина, имеющего идентификатор $\mathrm{termID}$, вида 
$<(\mathrm{docID}_0, \mathrm{positions}_0), \ldots>$ на кусочки. 
Хранить эти кусочки можно отдельно используя в качестве ключа для
$<(\mathrm{docID}_n, \mathrm{positions}_n), \ldots>$
кортеж $<\mathrm{termID}, \mathrm{docID}_n>$. Таким образом найти 
первый кусок для заданного термина можно за $O(\log(\mathrm{numberOfTerms}))$, 
найти кусок, соответствующий определенному документу
можно за $O(\log(\mathrm{numberOfBits}[\mathrm{termID}]))$, а итерация по списку 
вхождений для заданного термина требует $O(\mathrm{numberOfBits}[\mathrm{termID}])$, 
при этом всегда достаточно хранить в памяти только один кусок.

Хранить каждое вхождение $(\mathrm{docID}_n, \mathrm{positions}_0)$ отдельно 
было сочтено нецелесообразным, потому как это повлечет дополнительные расходы по памяти, внесенные
базой данных, и увеличение времени итерации, поскольку для каждого следующего вхождение 
необходимо обращение к базе данных.

\paragraph{Сопутствующая информация} Для хранения словаря и списка k-грамм
использовалась обертка \emph{Berkeley DB JE Collections}, с применением <<ручной>> сериализации для
более эффективного использования памяти.

\subsection{Индексирование документов с позиционными данными}
\paragraph{Предобработка.} Перед индексированием выполнялось разбиение документов на токена 
с последующей нормализацией каждого отдельного токена в термин. 
Затем для всех пар вида: документ плюс входящий в него термин, создавался упорядоченный 
список номеров токенов $\mathrm{positions}$, под которыми данный термин встречался в данном документе.
Полученный поток вхождений, передавался далее алгоритму построения индекса.

\paragraph{Алгоритм построения индекса.}
Для построения индекса использовался алгоритм \emph{SPIMI} 
(Single-Pass In Memory Indexing), работающий за время пропорциональное числу вхождений
и относительно нетребовательный к оперативной памяти.
Кратко его можно описать следующим образом:
\begin{enumerate}
\item входной поток вхождений терминов в документы, поступающий в виде кортежей
 $(\mathrm{term}, \mathrm{docID}, \mathrm{positions})$, разбивается на отрезки, 
которые возможно обработать в оперативной памяти.
    \begin{enumerate}
        \item Для каждого отрезка $<(\mathrm{term}_i, \mathrm{docID}_i, \mathrm{positions}_i), \ldots >$
            строится обратный индекс используя любые стандартные структуры данных
        \item Термины вместе с соответствующими им списками вхождений
            упорядочиваются по алфавиту и сохраняются в отдельный файл во внешней памяти.
    \end{enumerate}
\item Списки из внешней затем сливаются по каждому отдельному термину.
Благодаря упорядоченности списков в отдельном файле по термину, и вхождений внутри 
списка по $\mathrm{docID}$. Сливание можно провести с затратами оперативной памяти, пропорциональными
числу отрезков, на которые оказался разбит поток. Аналогично алгоритму сортировки слиянием.
\end{enumerate}

Для создания временного словаря, и отображения термина в соответствующий список,
использовалась структура данных хэш-таблица, представленная в стандартной библиотеке
$Java$ классом $HashMap$. Для сериализации списков вхождений и позиций вхождений
использовалась библиотека \emph{protobuf}, предоставляющая весьма компактное представление данных.

Заметим, что формат хранения позволяет легко добавлять новые документы (
в предположении что значения $\mathrm{docID}$ постоянно растут).
Для конкретного термина, добавление к списку вхождений новых элементов также требует хранить в памяти
только один кусочек из списка вхождений (подробнее о представлении списков памяти в предыдущем разделе).

\subsection{Поиск в индексе соответствующих запросу документов}

\paragraph{Позиционные запросы.}  Основу реализации требуемых запросов составила
абстракция \emph{Iterator<Posting>}, где каждый элемент \emph{Posting} представлял 
собой список вхождений некоторого подзапроса в какой-то определенный документ
вместе с позицией начала и конца этого вхождения. Ключевым моментом
являлась упорядоченность \emph{Posting} по идентификатору документа.

Данная абстракция была реализована в ленивой форме: каждый следующий элемент 
абстракции для подзапроса не вычисляется, пока это того не требуется для получения
некоторого документа запроса в целом. Ленивость позволила выполнять запросы 
с заданным ограничением на количество найденных документов без лишних вычислений,
и не совершая лишних запросов к базе данных.

\paragraph{Конъюнкция запросов} Конъюнкция запросов реализована с помощью
сливанием упорядоченных списков, представленные \emph{Iterator<Posting>}, которая 
естественным образом поддерживает ленивую итерацию.

\paragraph{Цитатные запросы и запросы с указанием близости.} Цитатные запросы, есть
ни что иное, как запросы с нулевой близостью вхождений плюс сохранение порядка
и запрет на пересечение подзапросов. Запросы с указанием близости реализованы на
основе конъюнкции запросов, но при этом информация о началах и концах вхождений
соответствующим образом анализируется и сливается в новый \emph{Posting}.

\paragraph{Запросы с метасимволами}. Для выполнения запросов с метасимволами был
реализован алгоритм, использующий k-граммы (если быть более точным --- триграммы) для 
поиска потенциально удовлетворяющих паттерну запроса терминов.
Если в запросе встречался паттерн-токен с метасимволами, то из него извлекались все известные триграммы
со спец-символами в начале и конце:
$$
    \mathbf{str*trup} \rightarrow \left\lbrace \$st, str, tru, rup, up\$ \right\rbrace
$$
Для каждой из триграмм, из базы данных запрашивался упорядоченный список 
идентификаторов терминов, в которых встречались данные триграммы. 
Затем данные списки пересекались, используя алгоритм сходный с сортировкой слиянием.
Получившиеся термины проверялись на соответствие паттерну, и дизъюнкция 
списков вхождений отфильтрованных терминов, возвращалась в виде абстракции \emph{Iterator<Posting>}.

\paragraph{Грамматика запросов.} Примерно так выглядит грамматика запросов:
$$
\begin{array}{l}
\mathbf{query} \rightarrow \mathbf{phrase}+ \\
\mathbf{phrase} \rightarrow \mathbf{subquery} \quad | \quad  \mathbf{subquery} \ /\mathrm{proximity}\ \mathbf{subquery} \\
\mathbf{subquery} \rightarrow \mathrm{word} \quad | \quad "\mathrm{word}+"
\end{array}
$$

Во время разбора запроса, создаются и комбинируются соответствующие реализации абстракции
\emph{Iterator<Posting>}. Из полученного результата затем извлекается необходимое количество документов.

\section{Результаты}
Реализация индекса работает корректно, построение индекса возможно с 
ограниченным объемом оперативной памяти (проверялось установкой флага \emph{-Xmx}
для \emph{Java Virtual Machine}).

На тестовых данных почти все требуемые виды запросов выполняются корректно,
исключения составляют запросы с метасимволами. 

Ответы на данные запросы иногда ошибочны, потому как в индексе, в целях экономии памяти, 
хранятся только нормализованные термины и списки вхождений триграмм строится для них. 
Чтобы в данной ситуации можно было искать
термины с учетом метасимволов, решено было токены, включающие метасиволы, также
нормализовать, и соответствие терминов паттерну производится для нормализованных токенов, 
что может приводить к присутствию в конечном запросе терминов,
денормализация которых не соответствует исходному паттерну.
\section{Заключение}
Поставленные задачи в целом решены. Результат интеграции с системой нормализации и
исправлении ошибок, позволяет осуществлять поиск документов, 
соответствующих обозначенным в постановке задачи запросам пользователей.
\end{document}